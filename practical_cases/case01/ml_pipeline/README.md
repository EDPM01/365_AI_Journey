# ğŸ¤– Pipeline de Machine Learning - MegaMercado

Un pipeline completo y robusto para el entrenamiento, evaluaciÃ³n y deployment de modelos de Machine Learning para el sistema de predicciÃ³n de demanda de MegaMercado.

## ğŸ¯ CaracterÃ­sticas Principales

- **ğŸ”„ Pipeline Automatizado**: Preprocesamiento, entrenamiento y evaluaciÃ³n automÃ¡tica
- **ğŸ¤– MÃºltiples Modelos**: Soporte para 10+ algoritmos de ML
- **ğŸ“Š EvaluaciÃ³n Completa**: MÃ©tricas detalladas y visualizaciones
- **ğŸ› ï¸ ConfiguraciÃ³n Flexible**: Ambientes de desarrollo y producciÃ³n
- **ğŸ“ˆ Monitoreo**: Tracking de performance y drift detection
- **ğŸš€ CLI Integrado**: Interfaz de lÃ­nea de comandos para automatizaciÃ³n

## ğŸ—ï¸ Arquitectura del Pipeline

```
ml_pipeline/
â”œâ”€â”€ ğŸ“ Core Components
â”‚   â”œâ”€â”€ config.py              # Configuraciones centralizadas
â”‚   â”œâ”€â”€ preprocessor.py        # Preprocesamiento de datos
â”‚   â”œâ”€â”€ model_trainer.py       # Entrenamiento de modelos
â”‚   â””â”€â”€ pipeline.py           # Orquestador principal
â”‚
â”œâ”€â”€ ğŸ“ Automation & CLI
â”‚   â”œâ”€â”€ automation.py         # AutomatizaciÃ³n y CLI
â”‚   â””â”€â”€ ejemplo_uso.py        # Ejemplos de uso
â”‚
â”œâ”€â”€ ğŸ“ Configuration
â”‚   â”œâ”€â”€ requirements.txt      # Dependencias
â”‚   â””â”€â”€ README.md            # Esta documentaciÃ³n
â”‚
â””â”€â”€ ğŸ“ Output Directories (creados automÃ¡ticamente)
    â”œâ”€â”€ data/               # Datos procesados
    â”œâ”€â”€ models/            # Modelos entrenados
    â”œâ”€â”€ reports/           # Reportes y grÃ¡ficas
    â””â”€â”€ logs/              # Logs de ejecuciÃ³n
```

## ğŸš€ Inicio RÃ¡pido

### 1. InstalaciÃ³n

```bash
# Clonar o navegar al directorio del pipeline
cd ml_pipeline

# Crear entorno virtual (recomendado)
python -m venv venv
source venv/bin/activate  # Linux/Mac
# venv\Scripts\activate   # Windows

# Instalar dependencias
pip install -r requirements.txt
```

### 2. Uso BÃ¡sico

```python
from pipeline import create_demand_prediction_pipeline

# Configurar rutas de datos
data_files = {
    'ventas': '../ventas.csv',
    'productos': '../productos.csv',
    'clientes': '../clientes.csv',
    'logistica': '../logistica.csv',
    'proveedores': '../proveedores.csv'
}

# Crear y ejecutar pipeline
pipeline = create_demand_prediction_pipeline(data_files, 'development')
results = pipeline.run_full_pipeline(
    data_files,
    target_column='cantidad_vendida',
    models_to_train=['random_forest', 'xgboost', 'linear_regression']
)

print(f"Mejor modelo: {results['training']['best_model']}")
```

### 3. Uso con CLI

```bash
# Ejecutar pipeline completo
python automation.py run --data-dir ../data --models random_forest xgboost

# Ejecutar experimentos en lote
python automation.py batch --data-dir ../data --config experiments.json

# Monitorear modelo existente
python automation.py monitor --model models/best_model.pkl --data new_data.csv
```

## ğŸ“‹ Modelos Soportados

| Modelo | Tipo | DescripciÃ³n |
|--------|------|-------------|
| **Linear Regression** | Lineal | RegresiÃ³n lineal bÃ¡sica |
| **Ridge Regression** | Lineal | RegresiÃ³n con regularizaciÃ³n L2 |
| **Lasso Regression** | Lineal | RegresiÃ³n con regularizaciÃ³n L1 |
| **Elastic Net** | Lineal | CombinaciÃ³n Ridge + Lasso |
| **Random Forest** | Ensemble | Bosque de Ã¡rboles de decisiÃ³n |
| **Gradient Boosting** | Ensemble | Boosting secuencial |
| **XGBoost** | Ensemble | Extreme Gradient Boosting |
| **LightGBM** | Ensemble | Light Gradient Boosting |
| **Support Vector Regression** | Kernel | RegresiÃ³n con SVM |
| **K-Nearest Neighbors** | Instance-based | RegresiÃ³n basada en vecinos |

## ğŸ”§ ConfiguraciÃ³n

### Ambientes Disponibles

#### Desarrollo (`development`)
- Entrenamiento rÃ¡pido
- Sin optimizaciÃ³n de hiperparÃ¡metros
- Logging detallado
- 3 folds de validaciÃ³n cruzada

#### ProducciÃ³n (`production`)
- OptimizaciÃ³n completa de hiperparÃ¡metros
- 5 folds de validaciÃ³n cruzada
- Logging mÃ­nimo
- EvaluaciÃ³n exhaustiva

### ConfiguraciÃ³n Personalizada

```python
from config import MLConfig

# Crear configuraciÃ³n personalizada
config_personalizada = {
    'TARGET_COLUMN': 'mi_target',
    'HYPERPARAMETER_TUNING': True,
    'CV_FOLDS': 5,
    'MODELS_CONFIG': {
        'random_forest': {
            'params': {'n_estimators': 200},
            'grid_search_params': {
                'max_depth': [10, 20, 30]
            }
        }
    }
}

# Usar en pipeline
pipeline = MLPipeline('development', config_personalizada)
```

## ğŸ“Š MÃ©tricas de EvaluaciÃ³n

El pipeline calcula automÃ¡ticamente las siguientes mÃ©tricas:

- **MAE** (Mean Absolute Error)
- **MSE** (Mean Squared Error)  
- **RMSE** (Root Mean Squared Error)
- **RÂ²** (Coefficient of Determination)
- **MAPE** (Mean Absolute Percentage Error)
- **Max Error** (Error mÃ¡ximo absoluto)

## ğŸ¨ Visualizaciones Generadas

### 1. ComparaciÃ³n de Modelos
- GrÃ¡ficas de barras comparando mÃ©tricas
- Rankings de performance
- AnÃ¡lisis de validaciÃ³n cruzada

### 2. AnÃ¡lisis de Predicciones
- Scatter plot: Predicciones vs Valores Reales
- AnÃ¡lisis de residuos
- DistribuciÃ³n de errores

### 3. Feature Importance
- Importancia de variables por modelo
- Rankings comparativos
- AnÃ¡lisis SHAP (si disponible)

## ğŸ”„ Flujo del Pipeline

```mermaid
graph TD
    A[Carga de Datos] --> B[ValidaciÃ³n y Limpieza]
    B --> C[Feature Engineering]
    C --> D[CodificaciÃ³n y Escalado]
    D --> E[DivisiÃ³n Train/Val/Test]
    E --> F[Entrenamiento Modelos]
    F --> G[ValidaciÃ³n Cruzada]
    G --> H[SelecciÃ³n Mejor Modelo]
    H --> I[EvaluaciÃ³n Final]
    I --> J[GeneraciÃ³n Reportes]
    J --> K[Guardado Modelos]
```

## ğŸ› ï¸ Preprocesamiento AutomÃ¡tico

### CaracterÃ­sticas Implementadas

1. **Manejo de Valores Faltantes**
   - ImputaciÃ³n por mediana (numÃ©ricos)
   - ImputaciÃ³n por moda (categÃ³ricos)

2. **DetecciÃ³n de Outliers**
   - MÃ©todo IQR (Rango IntercuartÃ­lico)
   - Z-Score para casos extremos

3. **Feature Engineering**
   - Features temporales automÃ¡ticos
   - Lag features configurables
   - Rolling windows
   - Features cÃ­clicos

4. **CodificaciÃ³n**
   - Label Encoding (muchas categorÃ­as)
   - One-Hot Encoding (pocas categorÃ­as)
   - Escalado estÃ¡ndar (variables numÃ©ricas)

## ğŸ“ Estructura de Salida

```
results/
â”œâ”€â”€ ğŸ“ models/                    # Modelos entrenados
â”‚   â”œâ”€â”€ best_model.pkl           # Mejor modelo
â”‚   â”œâ”€â”€ trained_models/          # Todos los modelos
â”‚   â””â”€â”€ model_comparison_report.csv
â”‚
â”œâ”€â”€ ğŸ“ reports/                  # Reportes y grÃ¡ficas
â”‚   â”œâ”€â”€ models_comparison.png
â”‚   â”œâ”€â”€ predictions_analysis.png
â”‚   â””â”€â”€ pipeline_report_*.json
â”‚
â”œâ”€â”€ ğŸ“ data/processed/          # Datos procesados
â”‚   â”œâ”€â”€ X_train.csv
â”‚   â”œâ”€â”€ X_test.csv
â”‚   â””â”€â”€ preprocessor.pkl
â”‚
â””â”€â”€ ğŸ“ logs/                    # Logs de ejecuciÃ³n
    â””â”€â”€ ml_pipeline_*.log
```

## ğŸ”® Uso para Predicciones

```python
# Cargar modelo entrenado
from pipeline import MLPipeline

pipeline = MLPipeline()
model = pipeline.trainer.load_model('models/best_model.pkl')

# Realizar predicciones
import pandas as pd
nuevos_datos = pd.read_csv('datos_nuevos.csv')
predicciones = pipeline.predict_new_data(nuevos_datos)

print(f"Predicciones: {predicciones}")
```

## ğŸ§ª Experimentos en Lote

Crear archivo `experiments.json`:

```json
{
  "experimento_basico": {
    "environment": "development",
    "models": ["linear_regression", "random_forest"]
  },
  "experimento_completo": {
    "environment": "production", 
    "models": ["random_forest", "xgboost", "lightgbm"]
  },
  "experimento_rapido": {
    "environment": "development",
    "models": ["linear_regression"]
  }
}
```

Ejecutar:
```bash
python automation.py batch --data-dir ../data --config experiments.json
```

## ğŸ“ˆ Monitoreo de Modelos

### ConfiguraciÃ³n de Umbrales

Crear `thresholds.json`:
```json
{
  "rmse_threshold": 100.0,
  "r2_threshold": 0.7,
  "mape_threshold": 15.0,
  "alert_email": "admin@megamercado.com"
}
```

### Monitoreo AutomÃ¡tico
```bash
python automation.py monitor \
  --model models/best_model.pkl \
  --data new_data.csv \
  --thresholds thresholds.json
```

## ğŸ”§ Casos de Uso EspecÃ­ficos

### 1. PredicciÃ³n de Demanda
```python
from pipeline import create_demand_prediction_pipeline

pipeline = create_demand_prediction_pipeline(data_files)
results = pipeline.run_full_pipeline(data_files)
```

### 2. SegmentaciÃ³n de Clientes
```python
from pipeline import create_customer_segmentation_pipeline

pipeline = create_customer_segmentation_pipeline(data_files)
results = pipeline.run_full_pipeline(data_files)
```

## ğŸš€ Deployment y ProducciÃ³n

### ProgramaciÃ³n AutomÃ¡tica
```bash
python automation.py schedule \
  --data-dir /path/to/data \
  --frequency daily \
  --models random_forest xgboost
```

### IntegraciÃ³n con API
El pipeline se puede integrar fÃ¡cilmente con APIs usando FastAPI:

```python
from fastapi import FastAPI
from pipeline import MLPipeline

app = FastAPI()
pipeline = MLPipeline()

@app.post("/predict")
async def predict(data: dict):
    predictions = pipeline.predict_new_data(pd.DataFrame(data))
    return {"predictions": predictions.tolist()}
```

## ğŸ› Troubleshooting

### Problemas Comunes

1. **Error de memoria**: Reducir `n_estimators` en Random Forest/XGBoost
2. **Datos faltantes**: Verificar que las columnas esperadas existan
3. **Performance lenta**: Usar configuraciÃ³n 'development' para pruebas
4. **Dependencias**: Instalar con `pip install -r requirements.txt`

### Logs Detallados

Los logs se guardan automÃ¡ticamente en `logs/ml_pipeline_*.log` con informaciÃ³n detallada sobre cada paso del pipeline.

## ğŸ¤ ContribuciÃ³n

Para contribuir al pipeline:

1. Fork el repositorio
2. Crea una rama para tu feature (`git checkout -b feature/nueva-funcionalidad`)
3. Commit tus cambios (`git commit -am 'AÃ±adir nueva funcionalidad'`)
4. Push a la rama (`git push origin feature/nueva-funcionalidad`)
5. Crea un Pull Request

## ğŸ“ Licencia

Este proyecto estÃ¡ bajo la Licencia MIT. Ver archivo `LICENSE` para mÃ¡s detalles.

## ğŸ™‹â€â™‚ï¸ Soporte

Para soporte tÃ©cnico o preguntas:

- ğŸ“§ Email: soporte@megamercado.com
- ğŸ“š DocumentaciÃ³n: [docs.megamercado.com](https://docs.megamercado.com)
- ğŸ› Issues: [GitHub Issues](https://github.com/megamercado/ml-pipeline/issues)

---

**MegaMercado ML Pipeline v1.0** - Sistema de Machine Learning para OptimizaciÃ³n de Inventarios y PredicciÃ³n de Demanda