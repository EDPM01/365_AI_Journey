# üßπ Pipeline de Limpieza de Datos

Una pipeline completa y flexible para la limpieza y procesamiento de datos CSV, dise√±ada espec√≠ficamente para el an√°lisis de datos de MegaMercado.

## üìÅ Estructura de Archivos

```
EDA/
‚îú‚îÄ‚îÄ data_cleaning_pipeline.py    # Clase principal de la pipeline
‚îú‚îÄ‚îÄ config.py                   # Configuraciones predefinidas
‚îú‚îÄ‚îÄ ejemplo_uso_pipeline.py      # Ejemplos de uso
‚îú‚îÄ‚îÄ README.md                   # Esta documentaci√≥n
‚îú‚îÄ‚îÄ data_cleaning.log           # Log de ejecuci√≥n (generado)
‚îî‚îÄ‚îÄ datos_limpios/              # Datos procesados (generado)
    ‚îú‚îÄ‚îÄ clientes_clean.csv
    ‚îú‚îÄ‚îÄ productos_clean.csv
    ‚îú‚îÄ‚îÄ ventas_clean.csv
    ‚îú‚îÄ‚îÄ logistica_clean.csv
    ‚îú‚îÄ‚îÄ proveedores_clean.csv
    ‚îî‚îÄ‚îÄ cleaning_report.txt
```

## üöÄ Caracter√≠sticas Principales

### ‚ú® Funcionalidades

- **Extracci√≥n autom√°tica**: Maneja archivos CSV y ZIP
- **Limpieza inteligente**: M√∫ltiples estrategias para valores faltantes
- **Detecci√≥n de outliers**: M√©todos IQR y Z-Score
- **Eliminaci√≥n de duplicados**: Con opciones de subset personalizado
- **Estandarizaci√≥n**: Tipos de datos y formato de texto
- **üîç Detecci√≥n de inconsistencias**: Sistema avanzado de validaci√≥n
- **Logging completo**: Seguimiento detallado del proceso
- **Reportes autom√°ticos**: An√°lisis de calidad antes y despu√©s
- **Configuraci√≥n flexible**: F√°cil personalizaci√≥n por dataset

### üö® Detecci√≥n de Inconsistencias

La pipeline incluye un **sistema avanzado de detecci√≥n de inconsistencias** que identifica:

#### üìù Tipos de Inconsistencias Detectadas

1. **Inconsistencias de Formato**
   - Emails inv√°lidos
   - Tel√©fonos mal formateados
   - Fechas con formato incorrecto
   - Inconsistencias de capitalizaci√≥n

2. **Inconsistencias de Rango**
   - Valores fuera de rangos esperados (edades negativas, etc.)
   - Valores negativos donde deber√≠an ser positivos
   - Rangos l√≥gicos violados

3. **Inconsistencias Temporales**
   - Fechas futuras en campos hist√≥ricos
   - Fechas muy antiguas (posibles errores)
   - Orden cronol√≥gico incorrecto entre fechas relacionadas

4. **Inconsistencias de Integridad Referencial**
   - Referencias a registros que no existen
   - Claves for√°neas hu√©rfanas
   - Violaciones de integridad entre tablas

5. **Inconsistencias Estad√≠sticas**
   - Valores que se repiten excesivamente
   - Patrones secuenciales sospechosos
   - Distribuciones an√≥malas

6. **Violaciones de Reglas de Negocio**
   - Reglas personalizadas por dominio
   - Validaciones espec√≠ficas del negocio
   - Restricciones l√≥gicas del sistema

#### üéØ Severidad de Inconsistencias

- **üî¥ CR√çTICAS**: Problemas que impiden el procesamiento (ej: referencias hu√©rfanas)
- **üü† ALTAS**: Problemas importantes que afectan la calidad (ej: rangos inv√°lidos)
- **üü° MEDIAS**: Problemas moderados que requieren atenci√≥n (ej: formatos inconsistentes)
- **üü¢ BAJAS**: Problemas menores de estandarizaci√≥n (ej: capitalizaci√≥n)

### üõ†Ô∏è Estrategias de Limpieza

1. **`drop_rows`**: Elimina filas con valores nulos (m√°s estricta)
2. **`drop_columns`**: Elimina columnas con muchos nulos
3. **`fill`**: Rellena valores faltantes con estrategias inteligentes
4. **`smart`**: Combina m√∫ltiples estrategias seg√∫n el contexto

## üìñ Uso R√°pido

### Ejemplo B√°sico

```python
from data_cleaning_pipeline import DataCleaningPipeline
from config import MEGAMERCADO_FILES, ECOMMERCE_CONFIG

# Configurar paths
BASE_PATH = "ruta/a/tus/datos"

# Crear pipeline
pipeline = DataCleaningPipeline(BASE_PATH)

# Ejecutar limpieza completa CON detecci√≥n de inconsistencias
clean_data = pipeline.run_complete_pipeline(
    MEGAMERCADO_FILES, 
    ECOMMERCE_CONFIG,
    detect_inconsistencies=True  # ¬°Activar detecci√≥n!
)

# Guardar resultados
pipeline.save_clean_data()
```

### Detecci√≥n de Inconsistencias Independiente

```python
from inconsistency_detector import InconsistencyDetector
import pandas as pd

# Crear detector
detector = InconsistencyDetector()

# Cargar datos
df = pd.read_csv('mi_dataset.csv')

# Detectar inconsistencias
inconsistencies = detector.detect_format_inconsistencies(df, 'mi_tabla')
inconsistencies.extend(detector.detect_range_inconsistencies(df, 'mi_tabla'))

# Ver resultados
for inc in inconsistencies:
    print(f"üö® {inc.type}: {inc.description}")
    print(f"   Casos: {inc.count}, Severidad: {inc.severity}")
```

### Configuraci√≥n de Reglas de Negocio

```python
from inconsistency_detector import InconsistencyDetector

# Crear detector
detector = InconsistencyDetector()

# Definir regla personalizada
def precio_valido(df):
    """El precio debe ser mayor a cero y menor a 10000"""
    return df[(df['precio'] <= 0) | (df['precio'] > 10000)]

# A√±adir regla
detector.add_business_rule('productos', 'precio_valido', precio_valido, 'HIGH')

# Definir integridad referencial
detector.add_reference_mapping('ventas', 'clientes', 'id_cliente', 'id_cliente')
```

### Limpieza R√°pida de un DataFrame

```python
from data_cleaning_pipeline import quick_clean_dataframe
import pandas as pd

# Cargar datos
df = pd.read_csv('datos_sucios.csv')

# Limpiar r√°pidamente
df_clean = quick_clean_dataframe(
    df, 
    strategy='smart',
    remove_duplicates=True
)
```

### An√°lisis de Calidad

```python
from data_cleaning_pipeline import analyze_dataset_quality
import pandas as pd

df = pd.read_csv('mi_dataset.csv')
analyze_dataset_quality(df, "Mi Dataset")
```

## ‚öôÔ∏è Configuraci√≥n

### Configuraci√≥n por Dataset

```python
mi_config = {
    'clientes': {
        'missing_strategy': 'smart',
        'missing_threshold': 0.7,
        'remove_outliers': True,
        'outlier_columns': ['edad', 'ingresos'],
        'outlier_method': 'iqr',
        'text_columns': ['nombre', 'email', 'direccion'],
        'type_mapping': {
            'fecha_registro': 'datetime',
            'activo': 'bool'
        },
        'fill_values': {
            'telefono': 'No disponible'
        },
        'duplicate_subset': ['id_cliente']
    }
}
```

### Configuraciones Predefinidas

```python
from config import (
    ECOMMERCE_CONFIG,     # Para datos de e-commerce
    FINANCIAL_CONFIG,     # Para datos financieros
    HEALTHCARE_CONFIG,    # Para datos de salud
    STRICT_CLEANING,      # Limpieza estricta
    PERMISSIVE_CLEANING,  # Limpieza permisiva
    BALANCED_CLEANING     # Limpieza balanceada
)
```

## üîß Par√°metros de Configuraci√≥n

### Estrategias de Valores Faltantes

| Par√°metro | Descripci√≥n | Valores |
|-----------|-------------|---------|
| `missing_strategy` | Estrategia para valores nulos | `'drop_rows'`, `'drop_columns'`, `'fill'`, `'smart'` |
| `missing_threshold` | Umbral para eliminar columnas | `0.0` - `1.0` |
| `fill_values` | Valores espec√≠ficos para rellenar | `Dict[str, Any]` |

### Detecci√≥n de Outliers

| Par√°metro | Descripci√≥n | Valores |
|-----------|-------------|---------|
| `remove_outliers` | Activar detecci√≥n de outliers | `True`, `False` |
| `outlier_columns` | Columnas a analizar | `List[str]` |
| `outlier_method` | M√©todo de detecci√≥n | `'iqr'`, `'zscore'` |
| `outlier_factor` | Factor multiplicador | `float` (ej: 1.5, 2.0, 3.0) |

### Procesamiento de Texto

| Par√°metro | Descripci√≥n | Valores |
|-----------|-------------|---------|
| `text_columns` | Columnas de texto a limpiar | `List[str]` |

### Tipos de Datos

| Par√°metro | Descripci√≥n | Valores |
|-----------|-------------|---------|
| `type_mapping` | Mapeo de tipos por columna | `Dict[str, str]` |

### Duplicados

| Par√°metro | Descripci√≥n | Valores |
|-----------|-------------|---------|
| `duplicate_subset` | Columnas para detectar duplicados | `List[str]` |

## üìä M√©tricas de Calidad

La pipeline proporciona m√©tricas autom√°ticas de calidad:

- **Completitud**: Porcentaje de valores no nulos
- **Consistencia**: Detecci√≥n de duplicados y formato
- **Validez**: Detecci√≥n de outliers y tipos incorrectos
- **Integridad**: Verificaci√≥n de referencias y restricciones

## üéØ Casos de Uso

### 1. E-commerce (MegaMercado)
```python
from config import ECOMMERCE_CONFIG, MEGAMERCADO_FILES

pipeline = DataCleaningPipeline(BASE_PATH)
clean_data = pipeline.run_complete_pipeline(MEGAMERCADO_FILES, ECOMMERCE_CONFIG)
```

### 2. Datos Financieros
```python
from config import FINANCIAL_CONFIG

config = FINANCIAL_CONFIG
# Personalizar seg√∫n necesidades espec√≠ficas
```

### 3. Limpieza Estricta
```python
from config import apply_strategy_to_all_datasets, STRICT_CLEANING

datasets = ['ventas', 'clientes', 'productos']
config = apply_strategy_to_all_datasets(datasets, STRICT_CLEANING)
```

## üö® Manejo de Errores

La pipeline incluye manejo robusto de errores:

- **Archivos faltantes**: Contin√∫a con otros datasets
- **Formato incorrecto**: Registra error y salta el archivo
- **Memoria insuficiente**: Optimizaci√≥n autom√°tica de tipos
- **Codificaci√≥n**: Detecci√≥n autom√°tica de encoding

## üìà Optimizaci√≥n de Performance

### Para Datasets Grandes

```python
# Configuraci√≥n optimizada para datasets grandes
config_optimizada = {
    'mi_dataset': {
        'missing_strategy': 'drop_columns',  # M√°s r√°pido
        'missing_threshold': 0.8,
        'remove_outliers': False,  # Desactivar si es muy lento
        'type_mapping': {
            'fecha': 'datetime64[ns]'  # M√°s eficiente
        }
    }
}
```

### Monitoreo de Memoria

```python
# La pipeline autom√°ticamente reporta uso de memoria
pipeline = DataCleaningPipeline(BASE_PATH, log_level='DEBUG')
```

## üîç Debugging

### Logs Detallados

```python
# Activar logging detallado
pipeline = DataCleaningPipeline(BASE_PATH, log_level='DEBUG')
```

### Revisi√≥n Manual

```python
# Verificar datos antes de guardar
clean_data = pipeline.run_complete_pipeline(files, config)

for name, df in clean_data.items():
    print(f"{name}: {df.shape}")
    print(df.head())
    print(df.info())
```

## üìù Ejemplos Completos

Ejecutar los ejemplos incluidos:

```bash
# Ejecutar todos los ejemplos de limpieza
python ejemplo_uso_pipeline.py

# Ejecutar ejemplos de detecci√≥n de inconsistencias
python ejemplo_deteccion_inconsistencias.py

# Solo ejemplo espec√≠fico (modificar el main())
python -c "from ejemplo_uso_pipeline import ejemplo_pipeline_completo; ejemplo_pipeline_completo()"
```

## ü§ù Contribuci√≥n

Para extender la pipeline:

1. **Nuevas estrategias**: A√±adir m√©todos a `DataCleaningPipeline`
2. **Configuraciones**: Agregar a `config.py`
3. **Validadores**: Implementar en `analyze_data_quality`
4. **Tipos de datos**: Extender `standardize_data_types`

## üìã Checklist de Limpieza

- [ ] ‚úÖ Valores faltantes manejados
- [ ] ‚úÖ Duplicados eliminados
- [ ] ‚úÖ Outliers detectados y tratados
- [ ] ‚úÖ Tipos de datos correctos
- [ ] ‚úÖ Texto estandarizado
- [ ] üîç **Inconsistencias detectadas y reportadas**
- [ ] üö® **Reglas de negocio validadas**
- [ ] üîó **Integridad referencial verificada**
- [ ] ‚úÖ Calidad validada
- [ ] ‚úÖ Reporte generado
- [ ] ‚úÖ Datos guardados

## üìÅ Archivos Generados

Despu√©s de ejecutar la pipeline con detecci√≥n de inconsistencias:

```
datos_limpios/
‚îú‚îÄ‚îÄ clientes_clean.csv           # Datos limpios
‚îú‚îÄ‚îÄ productos_clean.csv
‚îú‚îÄ‚îÄ ventas_clean.csv
‚îú‚îÄ‚îÄ logistica_clean.csv
‚îú‚îÄ‚îÄ proveedores_clean.csv
‚îú‚îÄ‚îÄ cleaning_report.txt          # Reporte de limpieza
‚îú‚îÄ‚îÄ inconsistencies_report.txt   # üÜï Reporte detallado de inconsistencias
‚îî‚îÄ‚îÄ data_cleaning.log           # Log completo del proceso
```

## üéØ Ejemplos de Inconsistencias Detectadas

### üìß Formato de Email Inv√°lido
```
üö® FORMAT_INCONSISTENCY
   Tabla: clientes
   Columna: email  
   Descripci√≥n: Valores que no siguen el formato esperado de email
   Casos: 3
   Ejemplos: ['pedro@invalid', 'jose@', 'ana@']
   Acci√≥n sugerida: Estandarizar formato o validar valores en columna email
```

### üî¢ Edad Fuera de Rango
```
üö® RANGE_INCONSISTENCY
   Tabla: clientes
   Columna: edad
   Descripci√≥n: Valores fuera del rango esperado (0-120)
   Casos: 2  
   Ejemplos: [-5, 200]
   Acci√≥n sugerida: Verificar y corregir valores fuera de rango en edad
```

### üîó Referencia Hu√©rfana
```
üö® REFERENTIAL_INTEGRITY_VIOLATION
   Tabla: ventas
   Columna: id_cliente
   Descripci√≥n: Referencias a clientes.id_cliente que no existen
   Casos: 2
   Ejemplos: [99, 88]
   Acci√≥n sugerida: Eliminar o corregir referencias hu√©rfanas en ventas.id_cliente
```

### ‚è∞ Orden Cronol√≥gico Incorrecto
```
üö® CHRONOLOGICAL_INCONSISTENCY  
   Tabla: ventas
   Columna: fecha_pedido vs fecha_entrega
   Descripci√≥n: fecha_pedido deber√≠a ser anterior a fecha_entrega
   Casos: 2
   Ejemplos: [{'fecha_pedido': '2024-01-15', 'fecha_entrega': '2024-01-10'}]
   Acci√≥n sugerida: Verificar orden cronol√≥gico entre fecha_pedido y fecha_entrega
```

## üéâ ¬°Listo!

Tu pipeline de limpieza est√° configurada y lista para usar. Los datos limpios estar√°n en `datos_limpios/` junto con un reporte detallado del proceso.

---
*Desarrollado para el proyecto 365_AI_Journey - Caso MegaMercado*