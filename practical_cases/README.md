# Caso Práctico: Optimizar inventarios y reducir costos operativos

## Contexto:

MegaMercado es una cadena de supermercados con presencia nacional, enfrenta el reto de optimizar sus inventarios y reducir costos operativos. Actualmente, los datos de ventas, logística y proveedores están dispersos en diferentes sistemas, lo que dificulta la toma de decisiones informadas. Se requiere una solución integral que permita la centralización, limpieza y análisis de estos datos, así como la generación de reportes y modelos predictivos para mejorar la gestión del inventario


## Objetivos del Caso

Los participantes deberán:

- Diseñar e implementar un pipeline de datos que integre información de distintas fuentes.

- Definir un esquema de almacenamiento eficiente para consultas y análisis.

- Realizar un análisis exploratorio de datos (EDA) y generar reportes interactivos.

- Construir y validar un modelo predictivo de demanda de productos.

- Desplegar una solución interactiva para visualización y consulta de datos.

-  Implementar control de versiones y documentación del proceso.

## Requisitos Técnicos

1. Pipeline de Datos (ETL)

- Extraer datos desde archivos CSV en la nube.

- Transformar y limpiar datos con Pandas, SQL y/o Spark.

- Cargar los datos en una base de datos centralizada (PostgreSQL, MongoDB, BigQuery, etc.).

2. Modelado y Almacenamiento de datos

- Diseñar un esquema eficiente de base de datos (modelo relacional y NoSQL).

- Implementar procedimientos de indexación y optimización de consultas.

3. Análisis Exploratorio y Visualización

- Realizar limpieza y validación de datos.

- Generar visualizaciones interactivas con Power BI, Tableau, Streamlit, etc.

4. Construcción de Modelos de aprendizaje

- Construir un modelo de machine learning para predicción de demanda usando Scikit-Learn, XGBoost,etc..

- Evaluar el modelo con métricas como RMSE, MAE y R^2.

5. Despliegue de Solución

- Desarrollar un API con FastAPI para consultas en tiempo real.

- Crear un dashboard interactivo con Streamlit o Dash.

6. Colaboración y Versionado

- Utilizar Git y GitHub/GitLab para versionamiento y trabajo en equipo.

- Incluir documentación clara del proceso y el código.

## Criterios de Evaluación

Cada participante será evaluado en los siguientes aspectos:

- Estructura y eficiencia del pipeline de datos (20%)

- Diseño del esquema de base de datos y optimización (15%)

- Calidad del análisis exploratorio y visualizaciones (15%)

- Precisión y robustez del modelo predictivo (20%)

- Funcionalidad del API o dashboard interactivo (15%)

- Colaboración, versionado y documentación (15%)

## Tiempo Estimado

Duración: 1 semana.

## Entregables

1. Repositorio de GitHub/GitLab:
   - Código fuente completo organizado por componentes
   -  Scripts SQL para creación y consulta de esquemas
   -  Notebooks con análisis exploratorio
   -  Modelos de ML entrenados o scripts para entrenarlos
   -  Código de la API y dashboard
   -  Documentación técnica

2. Documento de Diseño y Análisis (PDF) que incluya:
   - Diagrama de arquitectura
   - Decisiones de diseño y tecnológicas
   - Insights clave del análisis exploratorio
   - Evaluación de modelos predictivos
   - Recomendaciones de negocio basadas en los hallazgos

3. Presentación ejecutiva (5-7 diapositivas) que resuma:
   - Enfoque metodológico
   - Hallazgos principales
   - Solución propuesta
   - Valor de negocio proyectado

## Tecnologías Recomendadas
1. Base
   - Python (pandas, numpy, scikit-learn)
   - SQL (PostgreSQL)
   - Git y GitHub/GitLab

2. Ingeniería de Datos
   - Apache Airflow o Prefect (para orquestación)
   - dbt (para transformaciones)
   - SQLAlchemy (ORM)

3. Análisis y Visualización
   - Jupyter Notebooks
   - Matplotlib, Seaborn, Plotly
   - Tableau, Power BI, Looker Studio, Streamlit, etc.

4. Modelos de Aprendizaje
   - scikit-learn, XGBoost, LightGBM
   - TensorFlow o PyTorch (opcional para recomendaciones)
   - pandas-profiling, shap (para interpretabilidad)

5. Implementación
   - FastAPI o Flask
   - Streamlit o Dash
   - Docker (opcional)
   - Google Cloud Platform, AWS , Azure, Databricks (opcional)


## Consideraciones Adicionales

- Enfócate en la calidad sobre la cantidad
- Documenta los supuestos y limitaciones
- Explica claramente tu enfoque y decisiones
- Se valorará la escalabilidad de la solución propuesta


![freepik__the-style-is-candid-image-photography-with-natural__95240](https://github.com/user-attachments/assets/2769de3e-9290-4c9a-9eb5-e6685a72cd2e)




