# Pappers

## Agents
- Authors: Julia Wiesinger, Patrick Marlow and Vladimir Vuskovic
- This combination of reasoning, logic, and access to external information that are all connected to a Generative AI model invokes the concept of an agent.
- [Link](https://www.kaggle.com/whitepaper-agents)

## Foundational Large Language Models & Text Generation
- Authors: Mohammadamin Barektain, Anant Nawalgaria, Daniel J. Mankowitz, Majd Al Merey, Yaniv Leviathan, Massimo Mascaro, Matan Kalman, Elena Buchatskaya, Aliaksei Severyn, and Antonio Gulli
- We believe that this new crop of technologies has the potential to assist, complement, empower, and inspire people at any time across almost any field.
- [Link](https://www.kaggle.com/whitepaper-foundational-llm-and-text-generation)

## Attention Is All You Need
- Authors: Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Lukasz Kaiser, Illia Polosukhin
- In this work we propose the Transformer, a model architecture eschewing recurrence and instead relying entirely on an attention mechanism to draw global dependencies between input and output.
- [Link](https://arxiv.org/abs/1706.03762)

## Apple Intelligence Foundation Language Models
- Authors: Apple
- Introduced Foundation language models developed to power Apple Intelligence features. The foundation models are designed for Apple Intelligence, the personal intelligence system integrated into supported models of iPhone, iPad, and Mac.
- [Link](https://arxiv.org/pdf/2407.21075)



