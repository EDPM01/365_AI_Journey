# Pappers

## Agents
- Authors: Julia Wiesinger, Patrick Marlow and Vladimir Vuskovic
- This combination of reasoning, logic, and access to external information that are all connected to a Generative AI model invokes the concept of an agent.
- [Link](https://www.kaggle.com/whitepaper-agents)

## Foundational Large Language Models & Text Generation
- Authors: Mohammadamin Barektain, Anant Nawalgaria, Daniel J. Mankowitz, Majd Al Merey, Yaniv Leviathan, Massimo Mascaro, Matan Kalman, Elena Buchatskaya, Aliaksei Severyn, and Antonio Gulli
- We believe that this new crop of technologies has the potential to assist, complement, empower, and inspire people at any time across almost any field.
- [Link](https://www.kaggle.com/whitepaper-foundational-llm-and-text-generation)

## Attention Is All You Need
- Authors: Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Lukasz Kaiser, Illia Polosukhin
- In this work we propose the Transformer, a model architecture eschewing recurrence and instead relying entirely on an attention mechanism to draw global dependencies between input and output.
- [Link](https://arxiv.org/abs/1706.03762)

## Apple Intelligence Foundation Language Models
- Authors: Apple
- Introduced Foundation language models developed to power Apple Intelligence features. The foundation models are designed for Apple Intelligence, the personal intelligence system integrated into supported models of iPhone, iPad, and Mac.
- [Link](https://arxiv.org/pdf/2407.21075)


## 𝗦𝗶𝗺𝘂𝗹𝘁𝗮𝗻𝗲𝗼𝘂𝘀 𝗦𝗽𝗲𝗲𝗰𝗵-𝘁𝗼-𝗦𝗽𝗲𝗲𝗰𝗵 𝗧𝗿𝗮𝗻𝘀𝗹𝗮𝘁𝗶𝗼𝗻 𝘄𝗶𝘁𝗵 𝗮 𝗠𝘂𝗹𝘁𝗶𝘀𝘁𝗿𝗲𝗮𝗺 𝗠𝗼𝗱𝗲𝗹
- Authors: Tom Labiausse, Laurent Mazaré, Edouard Grave, Patrick Pérez, Alexandre Défossez, Neil Zeghidour
- Introduced Read this papper about introduces Hibiki, a model for simultaneous speech-to-speech and speech-to-text translation. Hibiki employs a multi-stream language model to simultaneously process source and target speech.
- [Link](https://arxiv.org/abs/2502.03382)

